{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cmsa.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1dyuYLmIEqXRGQg4Thm6a56eNAidp-Y4J","authorship_tag":"ABX9TyOypXCWXB/E9Etpwj9DxJ7R"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"7nSNbthf4mcM","colab_type":"code","colab":{}},"source":["import re\n","def token(sentence, remove_vowels=False, remove_repeat=False, minchars=2):\n","    tokens = []\n","#   for t in re.findall(\"[A-Z]{2,}(?![a-z])|[A-Z][a-z]+(?=[A-Z])|[\\w]+\",sentence.lower()):\n","    for t in re.findall(\"[a-zA-Z]+\",sentence.lower()):\n","\n","        if len(t)>=minchars:\n","            if remove_vowels:\n","                t=removeVovels(t)\n","            if remove_repeat:\n","                t=removeRepeat(t)\n","            tokens.append(t)\n","    return tokens\n","\n","VOWELS = ['a', 'e', 'i', 'o', 'u']\n","\n","def removeRepeat(string):\n","    return re.sub(r'(.)\\1+', r'\\1\\1', string)     \n","\n","def removeVovels(string):\n","    return ''.join([l for l in string.lower() if l not in VOWELS])\n","\n","if __name__ == '__main__':\n","    pass\n","\n","def normalize_matrix(matrix):\n","    pass"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XEW8U1Z_36c2","colab_type":"code","colab":{}},"source":["import numpy as np\n","import h5py\n","import pickle\n","from copy import deepcopy\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.preprocessing import sequence\n","from keras import backend as K\n","from keras.layers.core import Dense, Dropout, Activation\n","from keras.layers.embeddings import Embedding\n","from keras.layers.recurrent import LSTM, GRU\n","from keras.layers.convolutional import Convolution1D, MaxPooling1D\n","from keras.utils import np_utils"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0AKvTZji4OyT","colab_type":"code","colab":{}},"source":["################# GLOBAL VARIABLES #####################\n","#Filenames\n","#TODO: Add to coding conventions that directories are to always end with '/'\n","Masterdir = '/content/drive/My Drive/CMSA/'\n","Datadir = 'Data/'\n","Modeldir = 'Models/'\n","Featuredir = 'Features/'\n","inputdatasetfilename = 'IIITH_Codemixed.txt'\n","exp_details = 'new_experiment'\n","\n","#Data I/O formatting\n","SEPERATOR = '\\t'\n","DATA_COLUMN = 1\n","LABEL_COLUMN = 3\n","LABELS = ['0','1','2'] # 0 -> Negative, 1-> Neutral, 2-> Positive\n","mapping_char2num = {}\n","mapping_num2char = {}\n","MAXLEN = 200\n","\n","#LSTM Model Parameters\n","#Embedding\n","MAX_FEATURES = 0\n","embedding_size = 128\n","# Convolution\n","filter_length = 3\n","nb_filter = 128\n","pool_length = 3\n","# LSTM\n","lstm_output_size = 128\n","# Training\n","batch_size = 128\n","number_of_epochs = 50\n","numclasses = 3\n","test_size = 0.2\n","########################################################"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BNoR-fAQ6JAU","colab_type":"code","colab":{}},"source":["def parse(Masterdir,filename,seperator,datacol,labelcol,labels):\n","\t\"\"\"\n","\tPurpose -> Data I/O\n","\tInput   -> Data file containing sentences and labels along with the global variables\n","\tOutput  -> Sentences cleaned up in list of lists format along with the labels as a numpy array\n","\t\"\"\"\n","\t#Reads the files and splits data into individual lines\n","\tf=open(Masterdir+Datadir+filename,'r')\n","\tlines = f.read().lower()\n","\tlines = lines.lower().split('\\n')[:-1]\n","\n","\tX_train = []\n","\tY_train = []\n","\t\n","\t#Processes individual lines\n","\tfor line in lines:\n","\t\t# Seperator for the current dataset. Currently '\\t'. \n","\t\tline = line.split(seperator)\n","\t\t#Token is the function which implements basic preprocessing as mentioned in our paper\n","\t\ttokenized_lines = token(line[datacol])\n","\t\t\n","\t\t#Creates character lists\n","\t\tchar_list = []\n","\t\tfor words in tokenized_lines:\n","\t\t\tfor char in words:\n","\t\t\t\tchar_list.append(char)\n","\t\t\tchar_list.append(' ')\n","\t\t#print(char_list) - Debugs the character list created\n","\t\tX_train.append(char_list)\n","\t\t\n","\t\t#Appends labels\n","\t\tif line[labelcol] == labels[0]:\n","\t\t\tY_train.append(0)\n","\t\tif line[labelcol] == labels[1]:\n","\t\t\tY_train.append(1)\n","\t\tif line[labelcol] == labels[2]:\n","\t\t\tY_train.append(2)\n","\t\n","\t#Converts Y_train to a numpy array\t\n","\tY_train = np.asarray(Y_train)\n","\tassert(len(X_train) == Y_train.shape[0])\n","\n","\treturn [X_train,Y_train]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WzRMBsx36S9L","colab_type":"code","colab":{}},"source":["def convert_char2num(mapping_n2c,mapping_c2n,trainwords,maxlen):\n","\t\"\"\"\n","\tPurpose -> Convert characters to integers, a unique value for every character\n","\tInput   -> Training data (In list of lists format) along with global variables\n","\tOutput  -> Converted training data along with global variables\n","\t\"\"\"\n","\tallchars = []\n","\terrors = 0\n","\n","\t#Creates a list of all characters present in the dataset\n","\tfor line in trainwords:\n","\t\ttry:\n","\t\t\tallchars = set(allchars+line)\n","\t\t\tallchars = list(allchars)\n","\t\texcept:\n","\t\t\terrors += 1\n","\n","\t#print(errors) #Debugging\n","\t#print(allchars) #Debugging \n","\n","\t#Creates character dictionaries for the characters\n","\tcharno = 0\n","\tfor char in allchars:\n","\t\tmapping_char2num[char] = charno\n","\t\tmapping_num2char[charno] = char\n","\t\tcharno += 1\n","\n","\tassert(len(allchars)==charno) #Checks\n","\n","\t#Converts the data from characters to numbers using dictionaries \n","\tX_train = []\n","\tfor line in trainwords:\n","\t\tchar_list=[]\n","\t\tfor letter in line:\n","\t\t\tchar_list.append(mapping_char2num[letter])\n","\t\t#print(no) -- Debugs the number mappings\n","\t\tX_train.append(char_list)\n","\tprint(mapping_char2num)\n","\tprint(mapping_num2char)\n","\t#Pads the X_train to get a uniform vector\n","\t#TODO: Automate the selection instead of manual input\n","\tX_train = sequence.pad_sequences(X_train[:], maxlen=maxlen)\n","\treturn [X_train,mapping_num2char,mapping_char2num,charno]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8WYaOoqN6bDi","colab_type":"code","colab":{}},"source":["def RNN(X_train,y_train,args):\n","\t\"\"\"\n","\tPurpose -> Define and train the proposed LSTM network\n","\tInput   -> Data, Labels and model hyperparameters\n","\tOutput  -> Trained LSTM network\n","\t\"\"\"\n","\t#Sets the model hyperparameters\n","\t#Embedding hyperparameters\n","\tmax_features = args[0]\n","\tmaxlen = args[1]\n","\tembedding_size = args[2]\n","\t# Convolution hyperparameters\n","\tfilter_length = args[3]\n","\tnb_filter = args[4]\n","\tpool_length = args[5]\n","\t# LSTM hyperparameters\n","\tlstm_output_size = args[6]\n","\t# Training hyperparameters\n","\tbatch_size = args[7]\n","\tnb_epoch = args[8]\n","\tnumclasses = args[9]\n","\ttest_size = args[10] \n","\n","\t#Format conversion for y_train for compatibility with Keras\n","\ty_train = np_utils.to_categorical(y_train, numclasses) \n","\t#Train & Validation data splitting\n","\tX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=test_size, random_state=42)\n","\t\n","\t#Build the sequential model\n","\t# Model Architecture is:\n","\t# Input -> Embedding -> Conv1D+Maxpool1D -> LSTM -> LSTM -> FC-1 -> Softmaxloss\n","\tprint('Build model...')\n","\tmodel = Sequential()\n","\tmodel.add(Embedding(max_features, embedding_size, input_length=maxlen))\n","\tmodel.add(Convolution1D(nb_filter=nb_filter,\n","\t\t\t\t\t\t\tfilter_length=filter_length,\n","\t\t\t\t\t\t\tborder_mode='valid',\n","\t\t\t\t\t\t\tactivation='relu',\n","\t\t\t\t\t\t\tsubsample_length=1))\n","\tmodel.add(MaxPooling1D(pool_length=pool_length))\n","\tmodel.add(LSTM(lstm_output_size, dropout_W=0.2, dropout_U=0.2, return_sequences=True))\n","\tmodel.add(LSTM(lstm_output_size, dropout_W=0.2, dropout_U=0.2, return_sequences=False))\n","\tmodel.add(Dense(numclasses))\n","\tmodel.add(Activation('softmax'))\n","\n","\t# Optimizer is Adamax along with categorical crossentropy loss\n","\tmodel.compile(loss='categorical_crossentropy',\n","\t\t\t  \toptimizer='adamax',\n","\t\t\t  \tmetrics=['accuracy'])\n","\t\n","\n","\tprint('Train...')\n","\t#Trains model for 50 epochs with shuffling after every epoch for training data and validates on validation data\n","\tmodel.fit(X_train, y_train, \n","\t\t\t  batch_size=batch_size, \n","\t\t\t  shuffle=True, \n","\t\t\t  nb_epoch=nb_epoch,\n","\t\t\t  validation_data=(X_valid, y_valid))\n","\treturn model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TdY5E1k46hEj","colab_type":"code","colab":{}},"source":["def save_model(Masterdir,filename,model):\n","\t\"\"\"\n","\tPurpose -> Saves Keras model files to the given directory\n","\tInput   -> Directory and experiment details to be saved and trained model file\n","\tOutput  -> Nil\n","\t\"\"\"\n","\t#Referred from:- http://keras.io/getting-started/faq/#how-can-i-save-a-keras-model\n","\tmodel.save_weights(Masterdir+'Models/LSTM_'+filename+'_weights.h5')\n","\tjson_string = model.to_json()\n","\tf = open(Masterdir+'Models/'+'LSTM_'+filename+'_architecture.json','w')\n","\tf.write(json_string)\n","\tf.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_VhGFzR36i_j","colab_type":"code","colab":{}},"source":["def get_activations(model, layer, X_batch):\n","\t\"\"\"\n","\tPurpose -> Obtains outputs from any layer in Keras\n","\tInput   -> Trained model, layer from which output needs to be extracted & files to be given as input\n","\tOutput  -> Features from that layer \n","\t\"\"\"\n","\t#Referred from:- TODO: Enter the forum link from where I got this\n","\tget_activations = K.function([model.layers[0].input, K.learning_phase()], [model.layers[layer].output,])\n","\tactivations = get_activations([X_batch,0])\n","\treturn activations"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UvInN_cS6k_M","colab_type":"code","colab":{}},"source":["def evaluate_model(X_test,y_test,model,batch_size,numclasses):\n","\t\"\"\"\n","\tPurpose -> Evaluate any model on the testing data\n","\tInput   -> Testing data and labels, trained model and global variables\n","\tOutput  -> Nil\n","\t\"\"\"\n","\t#Convert y_test to one-hot encoding\n","\ty_test = np_utils.to_categorical(y_test, numclasses)\n","\t#Evaluate the accuracies\n","\tscore, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n","\tprint('Test score:', score)\n","\tprint('Test accuracy:', acc)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_gCasr_16nA7","colab_type":"code","colab":{}},"source":["def save_data(Masterdir,filename,X_train,X_test,y_train,y_test,features_train,features_test):\n","\t\"\"\"\n","\tPurpose -> Saves train, test data along with labels and features in the respective directories in the folder\n","\tInput   -> Train and test data, labels and features along with the directory and experiment details to be mentioned\n","\tOutput  -> Nil\n","\t\"\"\"\n","\th5f = h5py.File(Masterdir+Datadir+'Xtrain_'+filename+'.h5', 'w')\n","\th5f.create_dataset('dataset', data=X_train)\n","\th5f.close()\n","\n","\th5f = h5py.File(Masterdir+Datadir+'Xtest_'+filename+'.h5', 'w')\n","\th5f.create_dataset('dataset', data=X_test)\n","\th5f.close()\n","\n","\toutput = open(Masterdir+Datadir+'Ytrain_'+filename+'.pkl', 'wb')\n","\tpickle.dump([y_train], output)\n","\toutput.close()\n","\n","\toutput = open(Masterdir+Datadir+'Ytest_'+filename+'.pkl', 'wb')\n","\tpickle.dump([y_test], output)\n","\toutput.close()\n","\n","\th5f = h5py.File(Masterdir+Featuredir+'features_train_'+filename+'.h5', 'w')\n","\th5f.create_dataset('dataset', data=features_train)\n","\th5f.close()\n","\n","\th5f = h5py.File(Masterdir+Featuredir+'features_test_'+filename+'.h5', 'w')\n","\th5f.create_dataset('dataset', data=features_test)\n","\th5f.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SRVL9jaR6qmb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"70f5b682-c346-433b-8e9f-98b58a6fbf3c","executionInfo":{"status":"error","timestamp":1581000299232,"user_tz":-330,"elapsed":694620,"user":{"displayName":"Sourabh Deoghare","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAg1UNpHx5anG1QSdc-XG6pa1yOYsozFC07xKX4=s64","userId":"10496580796027792853"}}},"source":["if __name__ == '__main__':\n","\t\"\"\"\n","\tMaster function\n","\t\"\"\"\n","\tprint('Starting RNN Engine...\\nModel: Char-level LSTM.\\nParsing data files...')\n","\tout = parse(Masterdir,inputdatasetfilename,SEPERATOR,DATA_COLUMN,LABEL_COLUMN,LABELS)\n","\tX_train = out[0]\n","\ty_train = out[1]\n","\tprint('Parsing complete!')\n","\n","\tprint('Creating character dictionaries and format conversion in progess...')\n","\tout = convert_char2num(mapping_num2char,mapping_char2num,X_train,MAXLEN)\n","\tmapping_num2char = out[1]\n","\tmapping_char2num = out[2]\n","\tMAX_FEATURES = out[3]\n","\tX_train = np.asarray(out[0])\n","\ty_train = np.asarray(y_train).flatten()\n","\tprint('Complete!')\n","\t\n","\tprint('Splitting data into train and test...')\n","\tX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n","\tprint('X_train shape:', X_train.shape)\n","\tprint('X_test shape:', X_test.shape)\n","\t\n","\tprint('Creating LSTM Network...')\n","\tmodel = RNN(deepcopy(X_train),deepcopy(y_train),[MAX_FEATURES, MAXLEN, embedding_size,\\\n","\t\t\t     filter_length, nb_filter, pool_length, lstm_output_size, batch_size, \\\n","\t\t\t     number_of_epochs, numclasses, test_size])\n","\n","\tprint('Evaluating model...')\n","\tevaluate_model(X_test,deepcopy(y_test),model,batch_size,numclasses)\n","\t\n","\tprint('Feature extraction pipeline running...')\n","\tactivations = get_activations(model, 4, X_train)\n","\tfeatures_train = np.asarray(activations)\n","\tactivations = get_activations(model, 4, X_test)\n","\tfeatures_test = np.asarray(activations)\n","\tprint('Features extracted!')\n","\t\n","\tprint('Saving experiment...')\n","\tsave_model(Masterdir,exp_details,model)\n","\tsave_data(Masterdir,exp_details,X_train,X_test,y_train,y_test,features_train,features_test)\n","\tprint('Saved! Experiment finished!')"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Starting RNN Engine...\n","Model: Char-level LSTM.\n","Parsing data files...\n","Parsing complete!\n","Creating character dictionaries and format conversion in progess...\n","{'v': 0, 'm': 1, 'n': 2, 'i': 3, 'a': 4, 'j': 5, 'd': 6, 'z': 7, 'r': 8, 'y': 9, 'l': 10, 'b': 11, 'q': 12, 'w': 13, 'c': 14, 's': 15, 'o': 16, 'e': 17, 't': 18, 'g': 19, 'h': 20, 'x': 21, 'u': 22, 'k': 23, ' ': 24, 'f': 25, 'p': 26}\n","{0: 'v', 1: 'm', 2: 'n', 3: 'i', 4: 'a', 5: 'j', 6: 'd', 7: 'z', 8: 'r', 9: 'y', 10: 'l', 11: 'b', 12: 'q', 13: 'w', 14: 'c', 15: 's', 16: 'o', 17: 'e', 18: 't', 19: 'g', 20: 'h', 21: 'x', 22: 'u', 23: 'k', 24: ' ', 25: 'f', 26: 'p'}\n","Complete!\n","Splitting data into train and test...\n","X_train shape: (3103, 200)\n","X_test shape: (776, 200)\n","Creating LSTM Network...\n","Build model...\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=128, kernel_size=3, strides=1, padding=\"valid\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=3)`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, return_sequences=False, dropout=0.2, recurrent_dropout=0.2)`\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","Train...\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Train on 2482 samples, validate on 621 samples\n","Epoch 1/50\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","2482/2482 [==============================] - 16s 6ms/step - loss: 0.9896 - acc: 0.4980 - val_loss: 0.9869 - val_acc: 0.4815\n","Epoch 2/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.9649 - acc: 0.5105 - val_loss: 0.9979 - val_acc: 0.4815\n","Epoch 3/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.9550 - acc: 0.5145 - val_loss: 0.9782 - val_acc: 0.4847\n","Epoch 4/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.9465 - acc: 0.5242 - val_loss: 0.9725 - val_acc: 0.4831\n","Epoch 5/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.9240 - acc: 0.5435 - val_loss: 0.9696 - val_acc: 0.5056\n","Epoch 6/50\n","2482/2482 [==============================] - 14s 6ms/step - loss: 0.8999 - acc: 0.5741 - val_loss: 0.9402 - val_acc: 0.5330\n","Epoch 7/50\n","2482/2482 [==============================] - 14s 6ms/step - loss: 0.8795 - acc: 0.5761 - val_loss: 0.9153 - val_acc: 0.5459\n","Epoch 8/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.8690 - acc: 0.5983 - val_loss: 0.9082 - val_acc: 0.5572\n","Epoch 9/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.8494 - acc: 0.6100 - val_loss: 0.8985 - val_acc: 0.5636\n","Epoch 10/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.8441 - acc: 0.6156 - val_loss: 0.9003 - val_acc: 0.5572\n","Epoch 11/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.8330 - acc: 0.6148 - val_loss: 0.8948 - val_acc: 0.5620\n","Epoch 12/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.8205 - acc: 0.6338 - val_loss: 0.8672 - val_acc: 0.6006\n","Epoch 13/50\n","2482/2482 [==============================] - 14s 6ms/step - loss: 0.8058 - acc: 0.6418 - val_loss: 0.8633 - val_acc: 0.5942\n","Epoch 14/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.7987 - acc: 0.6394 - val_loss: 0.8692 - val_acc: 0.5717\n","Epoch 15/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.7990 - acc: 0.6422 - val_loss: 0.9529 - val_acc: 0.5749\n","Epoch 16/50\n","2482/2482 [==============================] - 14s 6ms/step - loss: 0.8003 - acc: 0.6394 - val_loss: 0.8497 - val_acc: 0.6006\n","Epoch 17/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.7768 - acc: 0.6507 - val_loss: 0.8399 - val_acc: 0.6071\n","Epoch 18/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.7659 - acc: 0.6632 - val_loss: 0.8573 - val_acc: 0.6006\n","Epoch 19/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.7597 - acc: 0.6575 - val_loss: 0.8423 - val_acc: 0.6119\n","Epoch 20/50\n","2482/2482 [==============================] - 14s 6ms/step - loss: 0.7439 - acc: 0.6628 - val_loss: 0.8596 - val_acc: 0.6087\n","Epoch 21/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.7504 - acc: 0.6660 - val_loss: 0.8374 - val_acc: 0.6135\n","Epoch 22/50\n","2482/2482 [==============================] - 14s 6ms/step - loss: 0.7277 - acc: 0.6809 - val_loss: 0.8242 - val_acc: 0.6184\n","Epoch 23/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.7237 - acc: 0.6861 - val_loss: 0.8194 - val_acc: 0.6135\n","Epoch 24/50\n","2482/2482 [==============================] - 14s 6ms/step - loss: 0.7234 - acc: 0.6934 - val_loss: 0.8286 - val_acc: 0.6023\n","Epoch 25/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.7095 - acc: 0.6986 - val_loss: 0.8402 - val_acc: 0.6103\n","Epoch 26/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.7232 - acc: 0.6732 - val_loss: 0.7977 - val_acc: 0.6216\n","Epoch 27/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.6908 - acc: 0.7047 - val_loss: 0.8046 - val_acc: 0.6184\n","Epoch 28/50\n","2482/2482 [==============================] - 13s 5ms/step - loss: 0.6798 - acc: 0.7115 - val_loss: 0.8503 - val_acc: 0.6296\n","Epoch 29/50\n","2482/2482 [==============================] - 14s 6ms/step - loss: 0.6779 - acc: 0.7079 - val_loss: 0.8015 - val_acc: 0.6280\n","Epoch 30/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.6576 - acc: 0.7087 - val_loss: 0.8344 - val_acc: 0.6280\n","Epoch 31/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.6595 - acc: 0.7156 - val_loss: 0.8100 - val_acc: 0.6345\n","Epoch 32/50\n","2482/2482 [==============================] - 13s 5ms/step - loss: 0.6497 - acc: 0.7232 - val_loss: 0.8244 - val_acc: 0.6200\n","Epoch 33/50\n","2482/2482 [==============================] - 14s 6ms/step - loss: 0.6493 - acc: 0.7192 - val_loss: 0.7897 - val_acc: 0.6409\n","Epoch 34/50\n","2482/2482 [==============================] - 13s 5ms/step - loss: 0.6292 - acc: 0.7321 - val_loss: 0.8037 - val_acc: 0.6409\n","Epoch 35/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.6321 - acc: 0.7264 - val_loss: 0.7942 - val_acc: 0.6361\n","Epoch 36/50\n","2482/2482 [==============================] - 13s 5ms/step - loss: 0.6345 - acc: 0.7284 - val_loss: 0.8023 - val_acc: 0.6441\n","Epoch 37/50\n","2482/2482 [==============================] - 13s 5ms/step - loss: 0.6163 - acc: 0.7413 - val_loss: 0.8067 - val_acc: 0.6393\n","Epoch 38/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.6123 - acc: 0.7389 - val_loss: 0.8036 - val_acc: 0.6232\n","Epoch 39/50\n","2482/2482 [==============================] - 13s 5ms/step - loss: 0.6181 - acc: 0.7333 - val_loss: 0.8567 - val_acc: 0.6345\n","Epoch 40/50\n","2482/2482 [==============================] - 13s 5ms/step - loss: 0.6133 - acc: 0.7353 - val_loss: 0.7984 - val_acc: 0.6473\n","Epoch 41/50\n","2482/2482 [==============================] - 13s 5ms/step - loss: 0.5863 - acc: 0.7458 - val_loss: 0.7924 - val_acc: 0.6538\n","Epoch 42/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.5941 - acc: 0.7546 - val_loss: 0.7958 - val_acc: 0.6554\n","Epoch 43/50\n","2482/2482 [==============================] - 13s 5ms/step - loss: 0.5834 - acc: 0.7554 - val_loss: 0.8048 - val_acc: 0.6554\n","Epoch 44/50\n","2482/2482 [==============================] - 14s 6ms/step - loss: 0.5761 - acc: 0.7494 - val_loss: 0.8132 - val_acc: 0.6651\n","Epoch 45/50\n","2482/2482 [==============================] - 14s 6ms/step - loss: 0.5627 - acc: 0.7611 - val_loss: 0.8285 - val_acc: 0.6361\n","Epoch 46/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.5705 - acc: 0.7550 - val_loss: 0.8133 - val_acc: 0.6441\n","Epoch 47/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.5596 - acc: 0.7619 - val_loss: 0.8779 - val_acc: 0.6586\n","Epoch 48/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.5401 - acc: 0.7780 - val_loss: 0.8329 - val_acc: 0.6441\n","Epoch 49/50\n","2482/2482 [==============================] - 13s 5ms/step - loss: 0.5694 - acc: 0.7579 - val_loss: 0.8905 - val_acc: 0.6441\n","Epoch 50/50\n","2482/2482 [==============================] - 14s 5ms/step - loss: 0.5597 - acc: 0.7558 - val_loss: 0.8391 - val_acc: 0.6522\n","Evaluating model...\n","776/776 [==============================] - 1s 1ms/step\n","Test score: 0.7921601423283213\n","Test accuracy: 0.6842783505154639\n","Feature extraction pipeline running...\n","Features extracted!\n","Saving experiment...\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-eb3ff730e90b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saving experiment...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMasterdir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexp_details\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0msave_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMasterdir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexp_details\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saved! Experiment finished!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-42018dd4e9e3>\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(Masterdir, filename, model)\u001b[0m\n\u001b[1;32m      6\u001b[0m \t\"\"\"\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m#Referred from:- http://keras.io/getting-started/faq/#how-can-i-save-a-keras-model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMasterdir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcharrnndir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'Models/LSTM_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mjson_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMasterdir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcharrnndir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'Models/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'LSTM_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_architecture.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'charrnndir' is not defined"]}]},{"cell_type":"code","metadata":{"id":"iBrYfRfe-7_V","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"8e75be54-75c8-44ff-f037-d01a2f9c2eb3","executionInfo":{"status":"ok","timestamp":1581000822479,"user_tz":-330,"elapsed":1245,"user":{"displayName":"Sourabh Deoghare","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAg1UNpHx5anG1QSdc-XG6pa1yOYsozFC07xKX4=s64","userId":"10496580796027792853"}}},"source":["print('Saving experiment...')\n","save_model(Masterdir,exp_details,model)\n","save_data(Masterdir,exp_details,X_train,X_test,y_train,y_test,features_train,features_test)\n","print('Saved! Experiment finished!')"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Saving experiment...\n","Saved! Experiment finished!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U88IDyCB--ka","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}