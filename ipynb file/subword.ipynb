{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7nSNbthf4mcM"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def token(sentence, remove_vowels=False, remove_repeat=False, minchars=2):\n",
    "    tokens = []\n",
    "#   for t in re.findall(\"[A-Z]{2,}(?![a-z])|[A-Z][a-z]+(?=[A-Z])|[\\w]+\",sentence.lower()):\n",
    "    for t in re.findall(\"[a-zA-Z]+\",sentence.lower()):\n",
    "\n",
    "        if len(t)>=minchars:\n",
    "            if remove_vowels:\n",
    "                t=removeVovels(t)\n",
    "            if remove_repeat:\n",
    "                t=removeRepeat(t)\n",
    "            tokens.append(t)\n",
    "    return tokens\n",
    "\n",
    "VOWELS = ['a', 'e', 'i', 'o', 'u']\n",
    "\n",
    "def removeRepeat(string):\n",
    "    return re.sub(r'(.)\\1+', r'\\1\\1', string)     \n",
    "\n",
    "def removeVovels(string):\n",
    "    return ''.join([l for l in string.lower() if l not in VOWELS])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pass\n",
    "\n",
    "def normalize_matrix(matrix):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XEW8U1Z_36c2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from keras import backend as K\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0AKvTZji4OyT"
   },
   "outputs": [],
   "source": [
    "################# GLOBAL VARIABLES #####################\n",
    "#Filenames\n",
    "#TODO: Add to coding conventions that directories are to always end with '/'\n",
    "Masterdir = 'C:/Users/DEEPAK KUMAR/Sub-word-LSTM-master'\n",
    "Datadir = 'Data/'\n",
    "Modeldir = 'Models/'\n",
    "Featuredir = 'Features/'\n",
    "inputdatasetfilename = 'IIITH_Codemixed.txt'\n",
    "exp_details = 'new_experiment'\n",
    "\n",
    "#Data I/O formatting\n",
    "SEPERATOR = '\\t'\n",
    "DATA_COLUMN = 1\n",
    "LABEL_COLUMN = 3\n",
    "LABELS = ['0','1','2'] # 0 -> Negative, 1-> Neutral, 2-> Positive\n",
    "mapping_char2num = {}\n",
    "mapping_num2char = {}\n",
    "MAXLEN = 200\n",
    "\n",
    "#LSTM Model Parameters\n",
    "#Embedding\n",
    "MAX_FEATURES = 0\n",
    "embedding_size = 128\n",
    "# Convolution\n",
    "filter_length = 3\n",
    "nb_filter = 128\n",
    "pool_length = 3\n",
    "# LSTM\n",
    "lstm_output_size = 128\n",
    "# Training\n",
    "batch_size = 128\n",
    "number_of_epochs = 50\n",
    "numclasses = 3\n",
    "test_size = 0.2\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BNoR-fAQ6JAU"
   },
   "outputs": [],
   "source": [
    "def parse(Masterdir,filename,seperator,datacol,labelcol,labels):\n",
    "\t\"\"\"\n",
    "\tPurpose -> Data I/O\n",
    "\tInput   -> Data file containing sentences and labels along with the global variables\n",
    "\tOutput  -> Sentences cleaned up in list of lists format along with the labels as a numpy array\n",
    "\t\"\"\"\n",
    "\t#Reads the files and splits data into individual lines\n",
    "\tf=open(\"IIITH_Codemixed.txt\",'r',encoding='utf-8')\n",
    "\tlines = f.read().lower()\n",
    "\tlines = lines.lower().split('\\n')[:-1]\n",
    "\n",
    "\tX_train = []\n",
    "\tY_train = []\n",
    "\t\n",
    "\t#Processes individual lines\n",
    "\tfor line in lines:\n",
    "\t\t# Seperator for the current dataset. Currently '\\t'. \n",
    "\t\tline = line.split(seperator)\n",
    "\t\t#Token is the function which implements basic preprocessing as mentioned in our paper\n",
    "\t\ttokenized_lines = token(line[datacol])\n",
    "\t\t\n",
    "\t\t#Creates character lists\n",
    "\t\tchar_list = []\n",
    "\t\tfor words in tokenized_lines:\n",
    "\t\t\tfor char in words:\n",
    "\t\t\t\tchar_list.append(char)\n",
    "\t\t\tchar_list.append(' ')\n",
    "\t\t#print(char_list) - Debugs the character list created\n",
    "\t\tX_train.append(char_list)\n",
    "\t\t\n",
    "\t\t#Appends labels\n",
    "\t\tif line[labelcol] == labels[0]:\n",
    "\t\t\tY_train.append(0)\n",
    "\t\tif line[labelcol] == labels[1]:\n",
    "\t\t\tY_train.append(1)\n",
    "\t\tif line[labelcol] == labels[2]:\n",
    "\t\t\tY_train.append(2)\n",
    "\t\n",
    "\t#Converts Y_train to a numpy array\t\n",
    "\tY_train = np.asarray(Y_train)\n",
    "\tassert(len(X_train) == Y_train.shape[0])\n",
    "\n",
    "\treturn [X_train,Y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WzRMBsx36S9L"
   },
   "outputs": [],
   "source": [
    "def convert_char2num(mapping_n2c,mapping_c2n,trainwords,maxlen):\n",
    "\t\"\"\"\n",
    "\tPurpose -> Convert characters to integers, a unique value for every character\n",
    "\tInput   -> Training data (In list of lists format) along with global variables\n",
    "\tOutput  -> Converted training data along with global variables\n",
    "\t\"\"\"\n",
    "\tallchars = []\n",
    "\terrors = 0\n",
    "\n",
    "\t#Creates a list of all characters present in the dataset\n",
    "\tfor line in trainwords:\n",
    "\t\ttry:\n",
    "\t\t\tallchars = set(allchars+line)\n",
    "\t\t\tallchars = list(allchars)\n",
    "\t\texcept:\n",
    "\t\t\terrors += 1\n",
    "\n",
    "\t#print(errors) #Debugging\n",
    "\t#print(allchars) #Debugging \n",
    "\n",
    "\t#Creates character dictionaries for the characters\n",
    "\tcharno = 0\n",
    "\tfor char in allchars:\n",
    "\t\tmapping_char2num[char] = charno\n",
    "\t\tmapping_num2char[charno] = char\n",
    "\t\tcharno += 1\n",
    "\n",
    "\tassert(len(allchars)==charno) #Checks\n",
    "\n",
    "\t#Converts the data from characters to numbers using dictionaries \n",
    "\tX_train = []\n",
    "\tfor line in trainwords:\n",
    "\t\tchar_list=[]\n",
    "\t\tfor letter in line:\n",
    "\t\t\tchar_list.append(mapping_char2num[letter])\n",
    "\t\t#print(no) -- Debugs the number mappings\n",
    "\t\tX_train.append(char_list)\n",
    "\tprint(mapping_char2num)\n",
    "\tprint(mapping_num2char)\n",
    "\t#Pads the X_train to get a uniform vector\n",
    "\t#TODO: Automate the selection instead of manual input\n",
    "\tX_train = sequence.pad_sequences(X_train[:], maxlen=maxlen)\n",
    "\treturn [X_train,mapping_num2char,mapping_char2num,charno]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8WYaOoqN6bDi"
   },
   "outputs": [],
   "source": [
    "def RNN(X_train,y_train,args):\n",
    "\t\"\"\"\n",
    "\tPurpose -> Define and train the proposed LSTM network\n",
    "\tInput   -> Data, Labels and model hyperparameters\n",
    "\tOutput  -> Trained LSTM network\n",
    "\t\"\"\"\n",
    "\t#Sets the model hyperparameters\n",
    "\t#Embedding hyperparameters\n",
    "\tmax_features = args[0]\n",
    "\tmaxlen = args[1]\n",
    "\tembedding_size = args[2]\n",
    "\t# Convolution hyperparameters\n",
    "\tfilter_length = args[3]\n",
    "\tnb_filter = args[4]\n",
    "\tpool_length = args[5]\n",
    "\t# LSTM hyperparameters\n",
    "\tlstm_output_size = args[6]\n",
    "\t# Training hyperparameters\n",
    "\tbatch_size = args[7]\n",
    "\tnb_epoch = args[8]\n",
    "\tnumclasses = args[9]\n",
    "\ttest_size = args[10] \n",
    "\n",
    "\t#Format conversion for y_train for compatibility with Keras\n",
    "\ty_train = np_utils.to_categorical(y_train, numclasses) \n",
    "\t#Train & Validation data splitting\n",
    "\tX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=test_size, random_state=42)\n",
    "\t\n",
    "\t#Build the sequential model\n",
    "\t# Model Architecture is:\n",
    "\t# Input -> Embedding -> Conv1D+Maxpool1D -> LSTM -> LSTM -> FC-1 -> Softmaxloss\n",
    "\tprint('Build model...')\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Embedding(max_features, embedding_size, input_length=maxlen))\n",
    "\tmodel.add(Convolution1D(filters=128,kernel_size=3,\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\tpadding='valid',\n",
    "\t\t\t\t\t\t\tactivation='relu',\n",
    "\t\t\t\t\t\t\tdilation_rate=1))\n",
    "\tmodel.add(MaxPooling1D(pool_length=pool_length))\n",
    "\tmodel.add(LSTM(lstm_output_size, dropout=0.2, return_sequences=True))\n",
    "\tmodel.add(LSTM(lstm_output_size, dropout=0.2, return_sequences=False))\n",
    "\tmodel.add(Dense(numclasses))\n",
    "\tmodel.add(Activation('softmax'))\n",
    "\n",
    "\t# Optimizer is Adamax along with categorical crossentropy loss\n",
    "\tmodel.compile(loss='categorical_crossentropy',\n",
    "\t\t\t  \toptimizer='adamax',\n",
    "\t\t\t  \tmetrics=['accuracy'])\n",
    "\t\n",
    "\n",
    "\tprint('Train...')\n",
    "\t#Trains model for 50 epochs with shuffling after every epoch for training data and validates on validation data\n",
    "\tmodel.fit(X_train, y_train, \n",
    "\t\t\t  batch_size=batch_size, \n",
    "\t\t\t  shuffle=True, \n",
    "\t\t\t  nb_epoch=nb_epoch,\n",
    "\t\t\t  validation_data=(X_valid, y_valid))\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TdY5E1k46hEj"
   },
   "outputs": [],
   "source": [
    "# def save_model(Masterdir,filename,model):\n",
    "# \t\"\"\"\n",
    "# \tPurpose -> Saves Keras model files to the given directory\n",
    "# \tInput   -> Directory and experiment details to be saved and trained model file\n",
    "# \tOutput  -> Nil\n",
    "# \t\"\"\"\n",
    "# \t#Referred from:- http://keras.io/getting-started/faq/#how-can-i-save-a-keras-model\n",
    "# \tmodel.save_weights(Masterdir+'Models/LSTM_'+filename+'_weights.h5')\n",
    "# \tjson_string = model.to_json()\n",
    "# \tf = open(Masterdir+'Models/'+'LSTM_'+filename+'_architecture.json','w')\n",
    "# \tf.write(json_string)\n",
    "# \tf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_VhGFzR36i_j"
   },
   "outputs": [],
   "source": [
    "# def get_activations(model, layer, X_batch):\n",
    "# \t\"\"\"\n",
    "# \tPurpose -> Obtains outputs from any layer in Keras\n",
    "# \tInput   -> Trained model, layer from which output needs to be extracted & files to be given as input\n",
    "# \tOutput  -> Features from that layer \n",
    "# \t\"\"\"\n",
    "# \t#Referred from:- TODO: Enter the forum link from where I got this\n",
    "# \tget_activations = K.function([model.layers[0].input, K.learning_phase()], [model.layers[layer].output,])\n",
    "# \tactivations = get_activations([X_batch,0])\n",
    "# \treturn activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UvInN_cS6k_M"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(X_test,y_test,model,batch_size,numclasses):\n",
    "\t\"\"\"\n",
    "\tPurpose -> Evaluate any model on the testing data\n",
    "\tInput   -> Testing data and labels, trained model and global variables\n",
    "\tOutput  -> Nil\n",
    "\t\"\"\"\n",
    "\t#Convert y_test to one-hot encoding\n",
    "\ty_test = np_utils.to_categorical(y_test, numclasses)\n",
    "\t#Evaluate the accuracies\n",
    "\tscore, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "\tprint('Test score:', score)\n",
    "\tprint('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_gCasr_16nA7"
   },
   "outputs": [],
   "source": [
    "# def save_data(Masterdir,filename,X_train,X_test,y_train,y_test,features_train,features_test):\n",
    "# \t\"\"\"\n",
    "# \tPurpose -> Saves train, test data along with labels and features in the respective directories in the folder\n",
    "# \tInput   -> Train and test data, labels and features along with the directory and experiment details to be mentioned\n",
    "# \tOutput  -> Nil\n",
    "# \t\"\"\"\n",
    "# \th5f = h5py.File(Masterdir+Datadir+'Xtrain_'+filename+'.h5', 'w')\n",
    "# \th5f.create_dataset('dataset', data=X_train)\n",
    "# \th5f.close()\n",
    "\n",
    "# \th5f = h5py.File(Masterdir+Datadir+'Xtest_'+filename+'.h5', 'w')\n",
    "# \th5f.create_dataset('dataset', data=X_test)\n",
    "# \th5f.close()\n",
    "\n",
    "# \toutput = open(Masterdir+Datadir+'Ytrain_'+filename+'.pkl', 'wb')\n",
    "# \tpickle.dump([y_train], output)\n",
    "# \toutput.close()\n",
    "\n",
    "# \toutput = open(Masterdir+Datadir+'Ytest_'+filename+'.pkl', 'wb')\n",
    "# \tpickle.dump([y_test], output)\n",
    "# \toutput.close()\n",
    "\n",
    "# \th5f = h5py.File(Masterdir+Featuredir+'features_train_'+filename+'.h5', 'w')\n",
    "# \th5f.create_dataset('dataset', data=features_train)\n",
    "# \th5f.close()\n",
    "\n",
    "# \th5f = h5py.File(Masterdir+Featuredir+'features_test_'+filename+'.h5', 'w')\n",
    "# \th5f.create_dataset('dataset', data=features_test)\n",
    "# \th5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 694620,
     "status": "error",
     "timestamp": 1581000299232,
     "user": {
      "displayName": "Sourabh Deoghare",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAg1UNpHx5anG1QSdc-XG6pa1yOYsozFC07xKX4=s64",
      "userId": "10496580796027792853"
     },
     "user_tz": -330
    },
    "id": "SRVL9jaR6qmb",
    "outputId": "70f5b682-c346-433b-8e9f-98b58a6fbf3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting RNN Engine...\n",
      "Model: Char-level LSTM.\n",
      "Parsing data files...\n",
      "Parsing complete!\n",
      "Creating character dictionaries and format conversion in progess...\n",
      "{'x': 0, 'm': 1, 'a': 2, 'p': 3, 'f': 4, 'n': 5, 'd': 6, 'u': 7, 'y': 8, 'q': 9, 'r': 10, 'c': 11, 'v': 12, 'l': 13, 'j': 14, 'h': 15, ' ': 16, 'z': 17, 'k': 18, 'e': 19, 't': 20, 's': 21, 'w': 22, 'i': 23, 'g': 24, 'o': 25, 'b': 26}\n",
      "{0: 'x', 1: 'm', 2: 'a', 3: 'p', 4: 'f', 5: 'n', 6: 'd', 7: 'u', 8: 'y', 9: 'q', 10: 'r', 11: 'c', 12: 'v', 13: 'l', 14: 'j', 15: 'h', 16: ' ', 17: 'z', 18: 'k', 19: 'e', 20: 't', 21: 's', 22: 'w', 23: 'i', 24: 'g', 25: 'o', 26: 'b'}\n",
      "Complete!\n",
      "Splitting data into train and test...\n",
      "X_train shape: (3103, 200)\n",
      "X_test shape: (776, 200)\n",
      "Creating LSTM Network...\n",
      "Build model...\n",
      "WARNING:tensorflow:From C:\\Users\\DEEPAK KUMAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEEPAK KUMAR\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=3)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DEEPAK KUMAR\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train...\n",
      "WARNING:tensorflow:From C:\\Users\\DEEPAK KUMAR\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEEPAK KUMAR\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:58: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2482 samples, validate on 621 samples\n",
      "Epoch 1/50\n",
      "2482/2482 [==============================] - 17s 7ms/step - loss: 0.9904 - acc: 0.5052 - val_loss: 0.9961 - val_acc: 0.4815\n",
      "Epoch 2/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.9671 - acc: 0.5097 - val_loss: 0.9832 - val_acc: 0.4928\n",
      "Epoch 3/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.9455 - acc: 0.5254 - val_loss: 0.9625 - val_acc: 0.4767\n",
      "Epoch 4/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.9172 - acc: 0.5479 - val_loss: 0.9372 - val_acc: 0.5427\n",
      "Epoch 5/50\n",
      "2482/2482 [==============================] - 9s 3ms/step - loss: 0.8883 - acc: 0.5898 - val_loss: 0.9098 - val_acc: 0.5475\n",
      "Epoch 6/50\n",
      "2482/2482 [==============================] - 9s 3ms/step - loss: 0.8752 - acc: 0.5838 - val_loss: 0.8981 - val_acc: 0.5700\n",
      "Epoch 7/50\n",
      "2482/2482 [==============================] - 9s 3ms/step - loss: 0.8483 - acc: 0.6035 - val_loss: 0.8926 - val_acc: 0.5749\n",
      "Epoch 8/50\n",
      "2482/2482 [==============================] - 8s 3ms/step - loss: 0.8417 - acc: 0.6140 - val_loss: 0.8792 - val_acc: 0.5862\n",
      "Epoch 9/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.8320 - acc: 0.6164 - val_loss: 0.8930 - val_acc: 0.5845\n",
      "Epoch 10/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.8265 - acc: 0.6237 - val_loss: 0.8611 - val_acc: 0.5878\n",
      "Epoch 11/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.8013 - acc: 0.6346 - val_loss: 0.8488 - val_acc: 0.6006\n",
      "Epoch 12/50\n",
      "2482/2482 [==============================] - 8s 3ms/step - loss: 0.7893 - acc: 0.6446 - val_loss: 0.8648 - val_acc: 0.5958\n",
      "Epoch 13/50\n",
      "2482/2482 [==============================] - 9s 3ms/step - loss: 0.7785 - acc: 0.6487 - val_loss: 0.8537 - val_acc: 0.6039\n",
      "Epoch 14/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.7779 - acc: 0.6507 - val_loss: 0.8395 - val_acc: 0.6103\n",
      "Epoch 15/50\n",
      "2482/2482 [==============================] - 8s 3ms/step - loss: 0.7766 - acc: 0.6543 - val_loss: 0.8351 - val_acc: 0.6200\n",
      "Epoch 16/50\n",
      "2482/2482 [==============================] - 9s 3ms/step - loss: 0.7444 - acc: 0.6825 - val_loss: 0.8361 - val_acc: 0.6151\n",
      "Epoch 17/50\n",
      "2482/2482 [==============================] - 9s 3ms/step - loss: 0.7542 - acc: 0.6688 - val_loss: 0.8370 - val_acc: 0.6216\n",
      "Epoch 18/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.7387 - acc: 0.6797 - val_loss: 0.8123 - val_acc: 0.6200\n",
      "Epoch 19/50\n",
      "2482/2482 [==============================] - 9s 3ms/step - loss: 0.7140 - acc: 0.6926 - val_loss: 0.8292 - val_acc: 0.6071\n",
      "Epoch 20/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.7131 - acc: 0.6898 - val_loss: 0.8599 - val_acc: 0.6216\n",
      "Epoch 21/50\n",
      "2482/2482 [==============================] - 9s 3ms/step - loss: 0.7107 - acc: 0.6934 - val_loss: 0.8930 - val_acc: 0.6071\n",
      "Epoch 22/50\n",
      "2482/2482 [==============================] - 9s 3ms/step - loss: 0.7217 - acc: 0.6793 - val_loss: 0.8219 - val_acc: 0.6151\n",
      "Epoch 23/50\n",
      "2482/2482 [==============================] - 9s 3ms/step - loss: 0.6746 - acc: 0.7063 - val_loss: 0.8696 - val_acc: 0.6248\n",
      "Epoch 24/50\n",
      "2482/2482 [==============================] - 8s 3ms/step - loss: 0.6770 - acc: 0.7071 - val_loss: 0.8074 - val_acc: 0.6377\n",
      "Epoch 25/50\n",
      "2482/2482 [==============================] - 9s 3ms/step - loss: 0.6637 - acc: 0.7135 - val_loss: 0.8051 - val_acc: 0.6457\n",
      "Epoch 26/50\n",
      "2482/2482 [==============================] - 9s 3ms/step - loss: 0.6734 - acc: 0.7115 - val_loss: 0.8372 - val_acc: 0.6280\n",
      "Epoch 27/50\n",
      "2482/2482 [==============================] - 8s 3ms/step - loss: 0.6601 - acc: 0.7248 - val_loss: 0.7986 - val_acc: 0.6361\n",
      "Epoch 28/50\n",
      "2482/2482 [==============================] - 8s 3ms/step - loss: 0.6650 - acc: 0.7063 - val_loss: 0.8132 - val_acc: 0.6329\n",
      "Epoch 29/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.6463 - acc: 0.7264 - val_loss: 0.7988 - val_acc: 0.6361\n",
      "Epoch 30/50\n",
      "2482/2482 [==============================] - 8s 3ms/step - loss: 0.6446 - acc: 0.7341 - val_loss: 0.8371 - val_acc: 0.6312\n",
      "Epoch 31/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.6386 - acc: 0.7268 - val_loss: 0.8226 - val_acc: 0.6329\n",
      "Epoch 32/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.5995 - acc: 0.7429 - val_loss: 0.8135 - val_acc: 0.6377\n",
      "Epoch 33/50\n",
      "2482/2482 [==============================] - 8s 3ms/step - loss: 0.6077 - acc: 0.7466 - val_loss: 0.8029 - val_acc: 0.6457\n",
      "Epoch 34/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.5852 - acc: 0.7482 - val_loss: 0.8250 - val_acc: 0.6441\n",
      "Epoch 35/50\n",
      "2482/2482 [==============================] - 9s 3ms/step - loss: 0.6021 - acc: 0.7498 - val_loss: 0.8214 - val_acc: 0.6457\n",
      "Epoch 36/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.5876 - acc: 0.7542 - val_loss: 0.8642 - val_acc: 0.6248\n",
      "Epoch 37/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.5935 - acc: 0.7409 - val_loss: 0.8397 - val_acc: 0.6345\n",
      "Epoch 38/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.5754 - acc: 0.7538 - val_loss: 0.8173 - val_acc: 0.6409\n",
      "Epoch 39/50\n",
      "2482/2482 [==============================] - 10s 4ms/step - loss: 0.5648 - acc: 0.7619 - val_loss: 0.8373 - val_acc: 0.6377\n",
      "Epoch 40/50\n",
      "2482/2482 [==============================] - 10s 4ms/step - loss: 0.5354 - acc: 0.7760 - val_loss: 0.8549 - val_acc: 0.6361\n",
      "Epoch 41/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.5632 - acc: 0.7675 - val_loss: 0.9513 - val_acc: 0.6248\n",
      "Epoch 42/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.5407 - acc: 0.7699 - val_loss: 0.8649 - val_acc: 0.6425\n",
      "Epoch 43/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.5347 - acc: 0.7736 - val_loss: 0.8374 - val_acc: 0.6634\n",
      "Epoch 44/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.5190 - acc: 0.7772 - val_loss: 0.8348 - val_acc: 0.6312\n",
      "Epoch 45/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.5140 - acc: 0.7800 - val_loss: 0.8531 - val_acc: 0.6264\n",
      "Epoch 46/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.5201 - acc: 0.7844 - val_loss: 0.8591 - val_acc: 0.6538\n",
      "Epoch 47/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.5021 - acc: 0.7897 - val_loss: 0.9667 - val_acc: 0.6312\n",
      "Epoch 48/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.4937 - acc: 0.7998 - val_loss: 0.8924 - val_acc: 0.6441\n",
      "Epoch 49/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.4689 - acc: 0.8082 - val_loss: 0.8765 - val_acc: 0.6329\n",
      "Epoch 50/50\n",
      "2482/2482 [==============================] - 9s 4ms/step - loss: 0.4642 - acc: 0.8054 - val_loss: 0.9623 - val_acc: 0.6473\n",
      "Evaluating model...\n",
      "776/776 [==============================] - 2s 2ms/step\n",
      "Test score: 0.936428895930654\n",
      "Test accuracy: 0.6701030927835051\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\t\"\"\"\n",
    "\tMaster function\n",
    "\t\"\"\"\n",
    "\tprint('Starting RNN Engine...\\nModel: Char-level LSTM.\\nParsing data files...')\n",
    "\tout = parse(Masterdir,inputdatasetfilename,SEPERATOR,DATA_COLUMN,LABEL_COLUMN,LABELS)\n",
    "\tX_train = out[0]\n",
    "\ty_train = out[1]\n",
    "\tprint('Parsing complete!')\n",
    "\n",
    "\tprint('Creating character dictionaries and format conversion in progess...')\n",
    "\tout = convert_char2num(mapping_num2char,mapping_char2num,X_train,MAXLEN)\n",
    "\tmapping_num2char = out[1]\n",
    "\tmapping_char2num = out[2]\n",
    "\tMAX_FEATURES = out[3]\n",
    "\tX_train = np.asarray(out[0])\n",
    "\ty_train = np.asarray(y_train).flatten()\n",
    "\tprint('Complete!')\n",
    "\t\n",
    "\tprint('Splitting data into train and test...')\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\tprint('X_train shape:', X_train.shape)\n",
    "\tprint('X_test shape:', X_test.shape)\n",
    "\t\n",
    "\tprint('Creating LSTM Network...')\n",
    "\tmodel = RNN(deepcopy(X_train),deepcopy(y_train),[MAX_FEATURES, MAXLEN, embedding_size,\\\n",
    "\t\t\t     filter_length, nb_filter, pool_length, lstm_output_size, batch_size, \\\n",
    "\t\t\t     number_of_epochs, numclasses, test_size])\n",
    "\n",
    "\tprint('Evaluating model...')\n",
    "\tevaluate_model(X_test,deepcopy(y_test),model,batch_size,numclasses)\n",
    "\t\n",
    "# \tprint('Feature extraction pipeline running...')\n",
    "# \tactivations = get_activations(model, 4, X_train)\n",
    "# \tfeatures_train = np.asarray(activations)\n",
    "# \tactivations = get_activations(model, 4, X_test)\n",
    "# \tfeatures_test = np.asarray(activations)\n",
    "# \tprint('Features extracted!')\n",
    "\t\n",
    "# \tprint('Saving experiment...')\n",
    "# \tsave_model(Masterdir,exp_details,model)\n",
    "# \tsave_data(Masterdir,exp_details,X_train,X_test,y_train,y_test,features_train,features_test)\n",
    "# \tprint('Saved! Experiment finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1245,
     "status": "ok",
     "timestamp": 1581000822479,
     "user": {
      "displayName": "Sourabh Deoghare",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAg1UNpHx5anG1QSdc-XG6pa1yOYsozFC07xKX4=s64",
      "userId": "10496580796027792853"
     },
     "user_tz": -330
    },
    "id": "iBrYfRfe-7_V",
    "outputId": "8e75be54-75c8-44ff-f037-d01a2f9c2eb3"
   },
   "outputs": [],
   "source": [
    "# print('Saving experiment...')\n",
    "# save_model(Masterdir,exp_details,model)\n",
    "# save_data(Masterdir,exp_details,X_train,X_test,y_train,y_test,features_train,features_test)\n",
    "# print('Saved! Experiment finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U88IDyCB--ka"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOypXCWXB/E9Etpwj9DxJ7R",
   "collapsed_sections": [],
   "mount_file_id": "1dyuYLmIEqXRGQg4Thm6a56eNAidp-Y4J",
   "name": "cmsa.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
